{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd240cc9-cb55-41da-9aaf-b462b0befec1",
   "metadata": {},
   "source": [
    "# 快速入门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243015ee-09bc-470f-af45-3b01b1a9b293",
   "metadata": {},
   "source": [
    "PyTorch 有两个用于处理数据的原语 ： torch.utils.data.DataLoader 和 torch.utils.data.Dataset 的 Dataset。 \n",
    "Dataset 存储示例及其相应的标签，DataLoader 围绕 Dataset 包装一个可迭代对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c83dae-2a1f-4675-b5b0-f73cdf501467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4d5139-47cc-4d68-b5f4-b589fdf26e72",
   "metadata": {},
   "source": [
    "PyTorch 提供特定于域的库，例如 TorchText、 TorchVision 和 TorchAudio，它们都包含数据集。在本教程中，我们将使用 TorchVision 数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe47f5-ffb4-4cdd-8e5b-cadf3d6d703e",
   "metadata": {},
   "source": [
    "torchvision.datasets 模块包含许多真实世界视觉数据（如 CIFAR、COCO）的数据集对象。在本教程中，我们使用 FashionMNIST 数据集。\n",
    "每个 TorchVision 数据集都包含两个参数：transform 和 target_transform 分别修改样品和标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43974930-3959-4b99-8ab8-f80a2f3e0907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 26.4M/26.4M [15:27<00:00, 28.5kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 29.5k/29.5k [00:00<00:00, 57.3kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.42M/4.42M [01:35<00:00, 46.4kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5.15k/5.15k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "# 从开放数据集下载训练数据\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    \n",
    ")\n",
    "# 从开放数据集下载测试数据\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac94e7f-a7c5-4c7d-a1dd-9e10ccdfc135",
   "metadata": {},
   "source": [
    "我们将 Dataset 作为参数传递给 DataLoader。这会在我们的数据集上包装一个可迭代对象，并支持自动批处理、采样、打乱和多进程数据加载。\n",
    "在这里，我们定义了 64 的批量大小，即 dataloader 可迭代对象中的每个元素将返回一批 64 个特征和标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb01134b-ac5f-4323-9d86-6f7d7f064ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X[N, C, H, W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y:torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# 创建 data loader\n",
    "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f'Shape of X[N, C, H, W]:{X.shape}')\n",
    "    print(f'Shape of y:{y.shape} {y.dtype}')\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd607263-f9a0-4c6b-a86d-3fc5967a9140",
   "metadata": {},
   "source": [
    "为了在 PyTorch 中定义神经网络，创建一个继承自__nn__的类  。在 __init__ 函数中定义网络层，并在正向函数中指定数据将如何通过网络。\n",
    "为了加速神经网络中的作，将其移动到加速器,例如 CUDA、MPS、MTIA 或 XPU。如果当前的加速器可用，使用它。否则，使用 CPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad3c1cb8-2ed1-4762-a160-6e8187c83136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27381f2b-34f9-48aa-bf82-998dae2a1d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    #前向传播\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7deefca-bb23-4772-a168-0e1d96e4e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <!-- 优化模型参数：要训练模型，需要一个损失函数和优化器 。 -->\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bb5106c-370f-455f-97c0-4d7ee8a26175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在单个训练循环中，模型对训练数据集进行预测（批量提供给它），并反向传播预测误差以调整模型的参数。\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        #计算误差\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        #后向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch%100 == 0:\n",
    "            loss, current = loss.item(), (batch+1) * len(X)\n",
    "            print(f'loss:{loss:>7f}  [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f5bb20d-07c6-4a52-9252-cf422758a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们还根据测试数据集检查模型的性能，以确保它正在学习。\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "565c7dbb-85d6-4cfb-a998-acb6ae46017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------------------------------\n",
      "loss:2.299602  [   64/60000]\n",
      "loss:2.289397  [ 6464/60000]\n",
      "loss:2.265764  [12864/60000]\n",
      "loss:2.277863  [19264/60000]\n",
      "loss:2.248036  [25664/60000]\n",
      "loss:2.220093  [32064/60000]\n",
      "loss:2.230238  [38464/60000]\n",
      "loss:2.194329  [44864/60000]\n",
      "loss:2.186302  [51264/60000]\n",
      "loss:2.164025  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 2.154938 \n",
      "\n",
      "Epoch 2\n",
      "------------------------------------------------------\n",
      "loss:2.159341  [   64/60000]\n",
      "loss:2.152780  [ 6464/60000]\n",
      "loss:2.091779  [12864/60000]\n",
      "loss:2.117631  [19264/60000]\n",
      "loss:2.053763  [25664/60000]\n",
      "loss:2.001616  [32064/60000]\n",
      "loss:2.027052  [38464/60000]\n",
      "loss:1.953698  [44864/60000]\n",
      "loss:1.949970  [51264/60000]\n",
      "loss:1.882244  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 1.879908 \n",
      "\n",
      "Epoch 3\n",
      "------------------------------------------------------\n",
      "loss:1.913227  [   64/60000]\n",
      "loss:1.885152  [ 6464/60000]\n",
      "loss:1.761379  [12864/60000]\n",
      "loss:1.804640  [19264/60000]\n",
      "loss:1.687967  [25664/60000]\n",
      "loss:1.646909  [32064/60000]\n",
      "loss:1.662215  [38464/60000]\n",
      "loss:1.574951  [44864/60000]\n",
      "loss:1.585883  [51264/60000]\n",
      "loss:1.484347  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.506171 \n",
      "\n",
      "Epoch 4\n",
      "------------------------------------------------------\n",
      "loss:1.574687  [   64/60000]\n",
      "loss:1.544344  [ 6464/60000]\n",
      "loss:1.385827  [12864/60000]\n",
      "loss:1.460553  [19264/60000]\n",
      "loss:1.335836  [25664/60000]\n",
      "loss:1.331406  [32064/60000]\n",
      "loss:1.344643  [38464/60000]\n",
      "loss:1.280245  [44864/60000]\n",
      "loss:1.301697  [51264/60000]\n",
      "loss:1.208098  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 1.238878 \n",
      "\n",
      "Epoch 5\n",
      "------------------------------------------------------\n",
      "loss:1.317097  [   64/60000]\n",
      "loss:1.304831  [ 6464/60000]\n",
      "loss:1.129171  [12864/60000]\n",
      "loss:1.240272  [19264/60000]\n",
      "loss:1.112250  [25664/60000]\n",
      "loss:1.129802  [32064/60000]\n",
      "loss:1.153786  [38464/60000]\n",
      "loss:1.101122  [44864/60000]\n",
      "loss:1.126140  [51264/60000]\n",
      "loss:1.051157  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.076079 \n",
      "\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "# 训练过程在多次迭代（ 纪元 ）中进行。在每个时期，模型都会学习参数以做出更好的预测。\n",
    "# 在每个时期打印模型的准确性和损失;我们希望看到准确性随着每个纪元的提高和损失的减少而减少。\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n------------------------------------------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b03dea-236f-48c6-b17f-1f92eaa8a9bd",
   "metadata": {},
   "source": [
    "保存模型\n",
    "保存模型的常用方法是序列化内部状态字典（包含模型参数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6acf69ee-db59-4daa-9a8b-f9f2862d99ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdcf411d-922a-48a2-b9a5-6da4c0f8ba3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型  加载模型的过程包括重新创建模型结构并将状态字典加载到其中\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1eaa2b8-babe-4294-b86c-240414e00b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Bag\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# 用该模型进行预测\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d0547-7233-4da7-8dad-b47d9c915c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
